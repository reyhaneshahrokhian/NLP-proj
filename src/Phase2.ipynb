{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessaries"
      ],
      "metadata": {
        "id": "sCMr4YeQt51x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3CB6OSnMQ88"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC_DI7ic8N5k",
        "outputId": "cd9c6970-40d1-4a7f-8d3b-de281d44e722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pji-c83G4lAv",
        "outputId": "cbb32465-7b27-4bad-a866-92c62817260a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2vec"
      ],
      "metadata": {
        "id": "O4pUX5nxtvw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(\"/content/drive/My Drive/output2017.csv\", \"r\") as f:\n",
        "    for row in csv.reader(f):\n",
        "        sentence = row[0]\n",
        "        tokenized_sentence = word_tokenize(sentence)\n",
        "        sentences.append(tokenized_sentence)\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "model.save(\"/content/drive/My Drive/models/2017.word2vec.npy\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = Word2Vec.load(\"/content/drive/My Drive/models/2017.word2vec.npy\")\n",
        "\n",
        "# Perform queries or generate reports using the loaded model\n",
        "similar_words = loaded_model.wv.most_similar(\"سال\", topn=20)\n",
        "\n",
        "# Generate a report\n",
        "dict_report = {word: similarity for word, similarity in similar_words}\n",
        "df = pd.DataFrame.from_dict(dict_report, orient=\"index\", columns=[\"Similarity\"])\n",
        "df.to_csv(\"/content/drive/My Drive/reports/2017_report.csv\", index_label=\"Word\")"
      ],
      "metadata": {
        "id": "crGcGvnQ4-gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(\"/content/drive/My Drive/output2020.csv\", \"r\") as f:\n",
        "    for row in csv.reader(f):\n",
        "        sentence = row[0]\n",
        "        tokenized_sentence = word_tokenize(sentence)\n",
        "        sentences.append(tokenized_sentence)\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "model.save(\"/content/drive/My Drive/models/2020.word2vec.npy\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = Word2Vec.load(\"/content/drive/My Drive/models/2020.word2vec.npy\")\n",
        "\n",
        "# Perform queries or generate reports using the loaded model\n",
        "similar_words = loaded_model.wv.most_similar(\"کرونا\", topn=20)\n",
        "\n",
        "# Generate a report\n",
        "dict_report = {word: similarity for word, similarity in similar_words}\n",
        "df = pd.DataFrame.from_dict(dict_report, orient=\"index\", columns=[\"Similarity\"])\n",
        "df.to_csv(\"/content/drive/My Drive/reports/2020_report.csv\", index_label=\"Word\")"
      ],
      "metadata": {
        "id": "yn_h3eaz8Im4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(\"/content/drive/My Drive/output2023.csv\", \"r\") as f:\n",
        "    for row in csv.reader(f):\n",
        "        sentence = row[0]\n",
        "        tokenized_sentence = word_tokenize(sentence)\n",
        "        sentences.append(tokenized_sentence)\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "model.save(\"/content/drive/My Drive/models/2023.word2vec.npy\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = Word2Vec.load(\"/content/drive/My Drive/models/2023.word2vec.npy\")\n",
        "\n",
        "# Perform queries or generate reports using the loaded model\n",
        "similar_words = loaded_model.wv.most_similar(\"اعدام\", topn=20)\n",
        "\n",
        "# Generate a report\n",
        "dict_report = {word: similarity for word, similarity in similar_words}\n",
        "df = pd.DataFrame.from_dict(dict_report, orient=\"index\", columns=[\"Similarity\"])\n",
        "df.to_csv(\"/content/drive/My Drive/reports/2023_report.csv\", index_label=\"Word\")\n"
      ],
      "metadata": {
        "id": "ISBMjMaN8Srt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(\"/content/drive/My Drive/outputAll.csv\", \"r\") as f:\n",
        "    for row in csv.reader(f):\n",
        "        sentence = row[0]\n",
        "        tokenized_sentence = word_tokenize(sentence)\n",
        "        sentences.append(tokenized_sentence)\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "model.save(\"/content/drive/My Drive/models/all.word2vec.npy\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = Word2Vec.load(\"/content/drive/My Drive/models/all.word2vec.npy\")\n",
        "\n",
        "# Perform queries or generate reports using the loaded model\n",
        "similar_words = loaded_model.wv.most_similar(\"عید\", topn=20)\n",
        "\n",
        "# Generate a report\n",
        "dict_report = {word: similarity for word, similarity in similar_words}\n",
        "df = pd.DataFrame.from_dict(dict_report, orient=\"index\", columns=[\"Similarity\"])\n",
        "df.to_csv(\"/content/drive/My Drive/reports/all_report.csv\", index_label=\"Word\")"
      ],
      "metadata": {
        "id": "S3baSnhZAbzi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}